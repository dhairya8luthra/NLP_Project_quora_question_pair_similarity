\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Problem Statement}{1}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Motivation}{1}{subsection.1.2}\protected@file@percent }
\citation{tfidf}
\citation{mikolov2013}
\citation{devlin2018bert}
\citation{reimers2019sentence}
\citation{dietterich2000ensemble}
\citation{wolpert1992stacked}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Dataset}{2}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Literature Review}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Traditional Approaches}{2}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Neural Embedding Methods}{2}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Transformer-Based Models}{2}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Feature Engineering for Text Similarity}{2}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Ensemble Learning}{3}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Exploratory Data Analysis}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Class Distribution}{3}{subsubsection.3.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Class distribution in the Quora Question Pairs dataset showing 36.9\% duplicate pairs and 63.1\% non-duplicate pairs.}}{3}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:eda_class}{{1}{3}{Class distribution in the Quora Question Pairs dataset showing 36.9\% duplicate pairs and 63.1\% non-duplicate pairs}{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Text Length Analysis}{3}{subsubsection.3.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Text length analysis comparing character lengths and word counts between duplicate and non-duplicate question pairs.}}{4}{figure.caption.2}\protected@file@percent }
\newlabel{fig:eda_length}{{2}{4}{Text length analysis comparing character lengths and word counts between duplicate and non-duplicate question pairs}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Word Overlap Patterns}{4}{subsubsection.3.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Word overlap analysis showing strong correlation between word share ratio and duplicate status.}}{4}{figure.caption.3}\protected@file@percent }
\newlabel{fig:eda_overlap}{{3}{4}{Word overlap analysis showing strong correlation between word share ratio and duplicate status}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.4}Question Frequency Analysis}{4}{subsubsection.3.1.4}\protected@file@percent }
\citation{henderson2017efficient}
\citation{schroff2015facenet}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Model Development Pipeline}{5}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Baseline Approaches}{5}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}TF-IDF with Logistic Regression}{5}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}SBERT Zero-Shot}{5}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Initial Approach: SBERT Fine-Tuning}{5}{subsection.3.4}\protected@file@percent }
\citation{schroff2015facenet}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Hard Negative Mining}{6}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Feature Engineering}{6}{subsection.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.1}Semantic Embedding Features (771 features)}{6}{subsubsection.3.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.2}Lexical Features (9 features)}{7}{subsubsection.3.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.3}Fuzzy Matching Features (6 features)}{7}{subsubsection.3.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.4}Linguistic Features (6 features)}{8}{subsubsection.3.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.5}TF-IDF Weighted Embeddings (3 features)}{8}{subsubsection.3.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Model Architecture}{8}{subsection.3.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.1}Base Models}{8}{subsubsection.3.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.2}Stacking Ensemble}{9}{subsubsection.3.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental Results}{9}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Performance Comparison}{9}{subsection.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Performance comparison of different approaches}}{9}{table.caption.4}\protected@file@percent }
\newlabel{tab:results}{{1}{9}{Performance comparison of different approaches}{table.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Progression Analysis}{10}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Comparative performance of different approaches showing progressive improvements through the development process.}}{10}{figure.caption.5}\protected@file@percent }
\newlabel{fig:progression}{{4}{10}{Comparative performance of different approaches showing progressive improvements through the development process}{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Impact of feature engineering on model performance demonstrating the value of combining multiple feature types.}}{10}{figure.caption.6}\protected@file@percent }
\newlabel{fig:features}{{5}{10}{Impact of feature engineering on model performance demonstrating the value of combining multiple feature types}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Ensemble vs Base Models}{11}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Base models versus stacking ensemble performance showing substantial improvement through model combination.}}{11}{figure.caption.7}\protected@file@percent }
\newlabel{fig:ensemble}{{6}{11}{Base models versus stacking ensemble performance showing substantial improvement through model combination}{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Performance metrics of the best stacking ensemble model across accuracy, F1 score, and ROC-AUC.}}{11}{figure.caption.8}\protected@file@percent }
\newlabel{fig:best_metrics}{{7}{11}{Performance metrics of the best stacking ensemble model across accuracy, F1 score, and ROC-AUC}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Error Analysis}{11}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{12}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Key Findings}{12}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Semantic Embeddings Are Crucial}{12}{subsubsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Fine-Tuning Requires Careful Consideration}{12}{subsubsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}Feature Engineering Adds Value}{12}{subsubsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.4}Ensemble Learning Provides Substantial Gains}{12}{subsubsection.5.1.4}\protected@file@percent }
\bibcite{tfidf}{1}
\bibcite{mikolov2013}{2}
\bibcite{devlin2018bert}{3}
\bibcite{reimers2019sentence}{4}
\bibcite{henderson2017efficient}{5}
\bibcite{dietterich2000ensemble}{6}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{13}{section.6}\protected@file@percent }
\bibcite{wolpert1992stacked}{7}
\bibcite{schroff2015facenet}{8}
\bibcite{godbole2017siamese}{9}
\bibcite{ansari2019quora}{10}
\gdef \@abspage@last{15}
